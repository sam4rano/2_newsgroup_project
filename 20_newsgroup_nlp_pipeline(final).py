# -*- coding: utf-8 -*-
"""20_newsgroup_nlp_pipeline(final).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lGNc70tari-5BD_ZZrGMQVy_htIN8Cx7

### Loading various libraries

1. ### ADDING ALL THE REQUIRED LIBRARY
"""

# Commented out IPython magic to ensure Python compatibility.
#warning handling
import warnings
warnings.filterwarnings('ignore')

#modelling
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier

#Evaluation
from sklearn.metrics import roc_curve, auc, confusion_matrix
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import classification_report

#exploration & feature engineering library
import pandas as pd
import numpy as np

#hyperparameter and sampling
from sklearn.pipeline import Pipeline
import random
from sklearn.model_selection import GridSearchCV

#preprocessing
import nltk
from nltk import word_tokenize
import re
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

from sklearn.feature_extraction.text import TfidfVectorizer



#visualisation library
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

#Loading the data set - training data.
from sklearn.datasets import fetch_20newsgroups

"""### Importing the 20newsgroup training data"""

# Load the 20 Newsgroups dataset
train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))

# Printing all the categories
train.target_names

# Finding frequency of each category
targets, frequency = np.unique(train.target, return_counts=True)
targets, frequency

targets_str = np.array(train.target_names)
print(list(zip(targets_str, frequency)))

# class distribution of the training set
fig=plt.figure(figsize=(10, 5), dpi= 80, facecolor='w', edgecolor='w')
plt.bar(targets_str,frequency, color='blue')
plt.xticks(rotation=90)
plt.title('Class distribution of 20 Newsgroups Training Data')
plt.xlabel('News Group')
plt.ylabel('Frequency')
plt.show()

"""# Feature Engineering of Training set"""

train = pd.DataFrame({'data':train.data, 'target':train.target})
train.head()

# Create a new column for the grouped categories
train['grouped_target'] = train['target'].replace({
    0: 'computer', 1: 'computer', 2: 'computer', 3: 'computer', 4: 'computer',
    5: 'computer', 6: 'misc', 7: 'autos', 8: 'motorcycles', 9: 'sports',
    10: 'sports', 11: 'science', 12: 'science', 13: 'science', 14: 'science',
    15: 'religion', 16: 'politics', 17: 'politics', 18: 'politics', 19: 'religion'
})

# Merge the 'computer', 'sports', 'politics', and 'religion' categories
train['merged_target'] = train['grouped_target'].replace({
    'computer': 'technology', 'sports': 'sports', 'politics': 'politics', 'religion': 'religion',
    'misc': 'other', 'science': 'other', 'autos': 'vehicles', 'motorcycles': 'vehicles'
})

# Drop the 'target_names' column
train = train.drop(columns=['target'])

# Drop the 'target_names' column
train = train.drop(columns=['grouped_target'])

train.head()

train['data'][:1]

# Printing all the categories
train.merged_target

# Finding frequency of each category
targets, frequency = np.unique(train.merged_target, return_counts=True)
targets, frequency

# create a figure and axis object
fig, ax = plt.subplots(figsize=(10, 6))

# plot the bar chart
ax.bar(targets, frequency, color='blue')

# set the axis labels and title
ax.set_xlabel('Category')
ax.set_ylabel('Frequency')
ax.set_title('Class distribution of 20 Newsgroups merged Data')

# rotate the x-axis labels for readability
plt.xticks(rotation=90)

# display the plot
plt.show()

"""# Loading & exploring test set"""

# Load the 20 Newsgroups dataset
test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))

# Printing all the categories
test.target_names

# Finding frequency of each category
targets, frequency = np.unique(test.target, return_counts=True)
targets, frequency

targets_str_test = np.array(test.target_names)
print(list(zip(targets_str_test, frequency)))

# class distribution of the test set
fig=plt.figure(figsize=(10, 5), dpi= 80, facecolor='w', edgecolor='w')
plt.bar(targets_str_test,frequency, color='maroon')
plt.xticks(rotation=90)
plt.title('Class distribution of 20 Newsgroups Testing Data')
plt.xlabel('News Group')
plt.ylabel('Frequency')
plt.show()

"""# # Feature Engineering of the test set"""

# Create a pandas dataframe from the dataset
test = pd.DataFrame({'text': test.data, 'target': test.target})

# Create a new column for the grouped categories
test['grouped_target'] = test['target'].replace({
    0: 'computer', 1: 'computer', 2: 'computer', 3: 'computer', 4: 'computer',
    5: 'computer', 6: 'misc', 7: 'autos', 8: 'motorcycles', 9: 'sports',
    10: 'sports', 11: 'science', 12: 'science', 13: 'science', 14: 'science',
    15: 'religion', 16: 'politics', 17: 'politics', 18: 'politics', 19: 'religion'
})

# Merge the 'computer', 'sports', 'politics', and 'religion' categories
test['merged_target'] = test['grouped_target'].replace({
    'computer': 'technology', 'sports': 'sports', 'politics': 'politics', 'religion': 'religion',
    'misc': 'other', 'science': 'other', 'autos': 'vehicles', 'motorcycles': 'vehicles'
})

# Drop the 'target_names' column
test = test.drop(columns=['target'])

# Drop the 'target_names' column
test = test.drop(columns=['grouped_target'])

test.head()

# Printing all the categories
test.merged_target

# Finding frequency of each category
targets_test, frequency_test = np.unique(test.merged_target, return_counts=True)
targets_test, frequency_test

# create a figure and axis object
fig, ax = plt.subplots(figsize=(10, 6))

# plot the bar chart
ax.bar(targets_test, frequency_test, color='blue')

# set the axis labels and title
ax.set_xlabel('Category')
ax.set_ylabel('Frequency')
ax.set_title('Class distribution of 20 Newsgroups merged test Data')

# rotate the x-axis labels for readability
plt.xticks(rotation=90)

# display the plot
plt.show()

"""# Data preparation

We will perform preparation steps such as Tokenization,Removing stopwords, Convert everything to lowercase, Stemming, Lemmatizing, and converting text data to a vector representation

# Data Cleaning
"""

# Define a function to preprocess the text
def preprocess_text(text):
    # Remove URLs
    text = re.sub(r"http\S+", "", text)
    # Remove special characters and punctuation
    text = re.sub(r'[^\w\s]', '', text)
    # Convert to lowercase
    text = text.lower()
    # Tokenize the text
    tokens = word_tokenize(text)
    # Remove stopwords
    tokens = [token for token in tokens if token not in stopwords.words('english')]
    # Lemmatize the tokens
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(token) for token in tokens]
    # Join the tokens back into a string
    text = " ".join(tokens)
    return text

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')

# Preprocess the text in the train and test sets
train['data'] = train['data'].apply(preprocess_text)

train = train.rename(columns={'data': 'text'})

train.head(20)

# Preprocess the text in the train and test sets
test['text'] = test['text'].apply(preprocess_text)

test.head(20)

"""# Count Vectorizer"""

# Extracting features from text files
from sklearn.feature_extraction.text import CountVectorizer

count_vect = CountVectorizer(stop_words='english')

X_train_cv = count_vect.fit_transform(train.text)  # fit_transform learns the vocab and one-hot encodes
X_test_cv = count_vect.transform(test.text) # transform uses the same vocab and one-hot encodes

print(X_train_cv.shape)
print(type(X_train_cv))

X_train_cv_df = pd.DataFrame(X_train_cv.todense())
X_train_cv_df.columns = sorted(count_vect.vocabulary_)
X_train_cv_df.head()

"""# TF-IDF Vectorizer"""

# Creating a document-term matrix using TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(stop_words='english')
# tfidfV = TfidfVectorizer(ngram_range=(1, 2), binary =True, stop_words='english')

X_train_tfidf = tfidf.fit_transform(train.text) # fit_transform learns the vocab and one-hot encodes
X_test_tfidf = tfidf.transform(test.text) # transform uses the same vocab and one-hot encodes

# print the dimensions of the training set (text messages, terms)
print(X_train_tfidf.shape)
print(type(X_train_tfidf))

X_train_tfidf = pd.DataFrame(X_train_tfidf.todense())
X_train_tfidf.columns = sorted(tfidf.vocabulary_)
X_train_tfidf.head()

"""# Classification Modelling count vectoriser"""

# Train and evaluate the Multinomial Naive Bayes classifier using count vectoriser
nb_clf = MultinomialNB()
y_train = train.merged_target
y_test = test.merged_target
nb_clf.fit(X_train_cv, y_train)
nb_pred = nb_clf.predict(X_test_cv)
nb_acc = accuracy_score(y_test, nb_pred)
print("Multinomial Naive Bayes accuracy:", nb_acc)

# Train and evaluate the SVM classifier using count vectoriser
svm_clf = LinearSVC()
y_train = train.merged_target
y_test = test.merged_target
svm_clf.fit(X_train_cv, y_train)
svm_pred = svm_clf.predict(X_test_cv)
svm_acc = accuracy_score(y_test, svm_pred)
print("SVM accuracy:", svm_acc)

# Train and evaluate the Multinomial Naive Bayes classifier count vectoriser
rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)
y_train = train.merged_target
y_test = test.merged_target
rf_clf.fit(X_train_cv, y_train)
rf_pred = rf_clf.predict(X_test_cv)
rf_acc = accuracy_score(y_test, rf_pred)
print("Random Forest accuracy:", rf_acc)

"""# Model Evaluation"""

# Print the classification report for each classifier
print("Naive Bayes Test Report:\n", classification_report(y_test, nb_pred))
print("Linear SVC Test Report:\n", classification_report(y_test, svm_pred))
print("Random Forest Test Report:\n", classification_report(y_test, rf_pred))

cm = confusion_matrix(y_test, nb_pred)
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion matrix for Multinomial Naive Bayes')
plt.show()

cm = confusion_matrix(y_test, svm_pred)
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion matrix for SVM')
plt.show()

cm = confusion_matrix(y_test, rf_pred)
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion matrix for Random forest')
plt.show()

"""# Classification Modelling using tfidf vectoriser"""

# Train and evaluate the Multinomial Naive Bayes classifier using tfidf vectoriser
nb_clf_tf = MultinomialNB()
y_train = train.merged_target
y_test = test.merged_target
nb_clf_tf.fit(X_train_tfidf, y_train)
nb_pred_tf = nb_clf_tf.predict(X_test_tfidf)
nb_acc = accuracy_score(y_test, nb_pred_tf)
print("Multinomial Naive Bayes accuracy:", nb_acc)

# Train and evaluate the SVM classifier using tfidf vectoriser
svm_clf_tf = LinearSVC()
y_train = train.merged_target
y_test = test.merged_target
svm_clf_tf.fit(X_train_tfidf, y_train)
svm_pred_tf = svm_clf_tf.predict(X_test_tfidf)
svm_acc = accuracy_score(y_test, svm_pred_tf)
print("SVM accuracy:", svm_acc)

# Train and evaluate the Multinomial Naive Bayes classifier tfidf vectoriser
rf_clf_tf = RandomForestClassifier(n_estimators=100, random_state=42)
y_train = train.merged_target
y_test = test.merged_target
rf_clf_tf.fit(X_train_tfidf, y_train)
rf_pred_tf = rf_clf_tf.predict(X_test_tfidf)
rf_acc_tf = accuracy_score(y_test, rf_pred_tf)
print("Random Forest accuracy:", rf_acc_tf)

# Print the classification report for each classifier
print("Naive Bayes Test Report:\n", classification_report(y_test, nb_pred_tf))
print("Linear SVC Test Report:\n", classification_report(y_test, svm_pred_tf))
print("Random Forest Test Report:\n", classification_report(y_test, rf_pred_tf))

cm = confusion_matrix(y_test, nb_pred_tf)
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion matrix for Multinomial Naive Bayes (tfidf)')
plt.show()

cm = confusion_matrix(y_test, svm_pred_tf)
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion matrix for SVM (tfidf)')
plt.show()

cm = confusion_matrix(y_test, rf_pred_tf)
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion matrix for Random forest (tfidf)')
plt.show()

#A confusion matrix consists of four categories: true positive (TP), true negative (TN), false positive (FP), and false negative (FN). These categories are defined as follows:

#True Positive (TP): The number of samples that are actually positive and are correctly predicted as positive by the model.
#True Negative (TN): The number of samples that are actually negative and are correctly predicted as negative by the model.
#False Positive (FP): The number of samples that are actually negative but are incorrectly predicted as positive by the model.
#False Negative (FN): The number of samples that are actually positive but are incorrectly predicted as negative by the model.
#The confusion matrix is typically displayed in a table format, where the rows represent the true class labels and the columns represent the predicted class labels. The number of samples that belong to each category is then displayed in the corresponding cell of the matrix.
#A confusion matrix can be used to calculate various performance metrics for a classification model, such as accuracy, precision, recall, and F1 score. It provides a more detailed view of the model's performance compared to a single performance metric, which makes it a useful tool for evaluating and fine-tuning machine learning models.

"""We can see that all of the categories have decent amount of samples and doesn't have high imbalance."""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.metrics import classification_report, accuracy_score
# 
# y_test = test.merged_target
# print('accuracy score Naive Bayes',accuracy_score(y_test, nb_pred))
# print('Naive bayes classification report')
# print(classification_report(y_test, nb_pred))

from sklearn.metrics import classification_report, accuracy_score

y_test = test.merged_target
print('accuracy score SVM',accuracy_score(y_test, svm_pred))
print('SVM classification report')
print(classification_report(y_test, svm_pred))

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.metrics import classification_report, accuracy_score
# 
# y_test = test.merged_target
# print('accuracy score SVM',accuracy_score(y_test, rf_pred))
# print('Random forest classification report')
# print(classification_report(y_test, rf_pred))

from sklearn.metrics import classification_report, accuracy_score

y_test = test.merged_target
print('accuracy score Naive Bayes',accuracy_score(y_test, nb_pred_tf))
print('Naive bayes classification report')
print(classification_report(y_test, nb_pred_tf))

from sklearn.metrics import classification_report, accuracy_score

y_test = test.merged_target
print('accuracy score SVM',accuracy_score(y_test, svm_pred_tf))
print('SVM classification report')
print(classification_report(y_test, svm_pred_tf))

from sklearn.metrics import classification_report, accuracy_score

y_test = test.merged_target
print('accuracy score Random forest',accuracy_score(y_test, rf_pred_tf))
print('Random forest classification report')
print(classification_report(y_test, rf_pred_tf))

"""## Using pipeline onwards to do the modeling

## I. Not using Stemming and Lemmatization

### 1. Terms in TF-IDF Vectorizer are unigrams (single words)
With TfidfVectorizer we can extract "bag of words" from the text and apply TF-IDF (term frequency - inverse document frequency) weights. Experimentaly we found that applying sublinear tf scaling (1 + log(tf)) improves overall results. We will first extract only unigrams from the text data to form the vectorizer.

### A. Using Multinominal Naive Bayes Model
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Performance of NB Classifier with No Stemming & Lemmatization
# text_clf = Pipeline([
#         ('vect', TfidfVectorizer(stop_words='english', sublinear_tf=True)), # CountVectorizer, TfidfVectorizer
#         ('clf', MultinomialNB())])  # MultinomialNB, LogisticRegression, SGDClassifier, KNeighborsClassifier
# 
# text_clf.fit(train.text, train.merged_target)
# print(text_clf.score(test.text,test.merged_target))
# print(classification_report(test.merged_target, text_clf.predict(test.text)))

"""### B. Using Support Vector Machine Model"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Performance of LR Classifier with No Stemming & Lemmatization
# text_clf = Pipeline([
#         ('vect', TfidfVectorizer(stop_words='english', sublinear_tf=True)), # TfidfVectorizer
#         ('clf', LinearSVC())])
# text_clf.fit(train.text,train.merged_target)
# print(text_clf.score(test.text, test.merged_target))
# print(classification_report(test.merged_target, text_clf.predict(test.text)))
#

"""**Performing grid search on the 'penalty' parameter of support vector machine Classifier. We get best performance when L2-norm is used in the penalization.**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Performing Grid Search to find best LR parameters
# pipeline = Pipeline([
#         ('vect', TfidfVectorizer(stop_words='english', sublinear_tf=True)), # TfidfVectorizer
#         ('clf', LinearSVC())]) #Support vector machine
# 
# parameters = {
#        'clf__penalty': ('l1', 'l2')
# }
# 
# grid_search = GridSearchCV(pipeline, parameters)
# grid_search.fit(train.text, train.merged_target)

# grid_search.cv_results_
print('Best training score %0.4f' % grid_search.best_score_)

print('Best parameters = ')
best_parameters = grid_search.best_estimator_.get_params()
for param_name in sorted(parameters.keys()):
    print("%s: %r" % (param_name, best_parameters[param_name]))

# Test Accuracy
grid_search.best_estimator_.score(test.text, test.merged_target)

"""### C. Using Random forest Classifier Model"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Performance of SGD Classifier with No Stemming & Lemmatization
# random.seed(1)
# text_clf = Pipeline([
#         ('vect', TfidfVectorizer(stop_words='english', sublinear_tf=True)), # CountVectorizer
#         ('clf', RandomForestClassifier())])  # RandomForestClassifier,
# text_clf.fit(train.text, train.merged_target)
# print(text_clf.score(test.text,test.merged_target))
# print(classification_report(test.merged_target, text_clf.predict(test.text)))

# grid_search.cv_results_
print('Best training score %0.4f' % grid_search.best_score_)

print('Best parameters = ')
best_parameters = grid_search.best_estimator_.get_params()
for param_name in sorted(parameters.keys()):
    print("%s: %r" % (param_name, best_parameters[param_name]))

# Test Accuracy
grid_search.best_estimator_.score(test.text, test.merged_target)

"""### 2. Terms in TF-IDF Vectorizer are unigrams and bigrams, and values are binary values
Now we will extract unigrams as well as bigrams from the text to form the TF-IDF vectorizer.
"""

